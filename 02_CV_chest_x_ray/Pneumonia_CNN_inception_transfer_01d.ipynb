{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NaMU2vWK4mnx",
   "metadata": {
    "executionInfo": {
     "elapsed": 2317,
     "status": "ok",
     "timestamp": 1642960877108,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "NaMU2vWK4mnx"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from numpy.random import seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array \n",
    "from os import listdir\n",
    "import os\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import urllib.request\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "H3M59yAEviwz",
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1642960888656,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "H3M59yAEviwz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "mpl.rcParams[\"xtick.labelsize\"] = 10\n",
    "mpl.rcParams[\"ytick.labelsize\"] = 10\n",
    "mpl.rcParams[\"axes.labelsize\"] = 10\n",
    "mpl.rcParams[\"axes.titlesize\"] = 14\n",
    "mpl.rcParams[\"legend.fontsize\"] = 10\n",
    "mpl.rcParams[\"figure.dpi\"] = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9EeBKNevBTkr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22429,
     "status": "ok",
     "timestamp": 1642960912751,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "9EeBKNevBTkr",
    "outputId": "0dd13569-6639-4957-876b-690575259c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pj6_8Xa_39Zw",
   "metadata": {
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1642960945468,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "pj6_8Xa_39Zw"
   },
   "outputs": [],
   "source": [
    "training_dir = '/content/drive/MyDrive/data science/02_chest_x_ray/image/train'\n",
    "validation_dir = '/content/drive/MyDrive/data science/02_chest_x_ray/image/val'\n",
    "test_dir = '/content/drive/MyDrive/data science/02_chest_x_ray/image/test'\n",
    "\n",
    "# training_dir = '/Volumes/GoogleDrive/My Drive/data science/02_chest_x_ray/image/train'\n",
    "# validation_dir = '/Volumes/GoogleDrive/My Drive/data science/02_chest_x_ray/image/val'\n",
    "# test_dir = '/Volumes/GoogleDrive/My Drive/data science/02_chest_x_ray/image/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f78683",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 20364,
     "status": "error",
     "timestamp": 1642960969103,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "b8f78683",
    "outputId": "a8d0ccca-5089-462d-f2ec-fd5c3fab9b51"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-410b3a9da660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         class_mode='binary')\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalidation_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mclasses_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mclasses_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add a step to convert the pictures to smaller size first\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=(300, 300),   \n",
    "        batch_size = 32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        batch_size = 32,\n",
    "        target_size=(300, 300),\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ityuBNFTjndg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2424,
     "status": "ok",
     "timestamp": 1642492692242,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "ityuBNFTjndg",
    "outputId": "37851330-2f3e-4d6e-9684-b484f9a175ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        batch_size = 32,\n",
    "        target_size=(300, 300),\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fWwzEfeVqby",
   "metadata": {
    "id": "5fWwzEfeVqby"
   },
   "outputs": [],
   "source": [
    "# this is the same file as just say weights = imageNet\n",
    "# weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "# weights_file = \"inception_v3.h5\"\n",
    "# urllib.request.urlretrieve(weights_url, weights_file)\n",
    "# pre_trained_model = InceptionV3(input_shape=(300, 300, 3), include_top=False, weights=None)\n",
    "# pre_trained_model.load_weights(weights_file)\n",
    "# for layer in pre_trained_model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcUi8Ps4Y12e",
   "metadata": {
    "id": "qcUi8Ps4Y12e"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# another call back function overwrite \n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if(logs.get('accuracy')>0.95):\n",
    "#             print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "#             self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mggkh9AfFq65",
   "metadata": {
    "id": "mggkh9AfFq65"
   },
   "outputs": [],
   "source": [
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1sn6pFJ_6He_",
   "metadata": {
    "id": "1sn6pFJ_6He_"
   },
   "source": [
    "Transfer learning with Inception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jHHhy8y8WAxb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6524,
     "status": "ok",
     "timestamp": 1642492710207,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "jHHhy8y8WAxb",
    "outputId": "d8a8d397-b8ec-4b6f-d4f2-63bc0b789e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "87924736/87910968 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# transfer learning\n",
    "# transfer learning with inception network\n",
    "pre_trained_model = InceptionV3(input_shape=(300, 300, 3), include_top=False, weights=\"imagenet\")\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "# print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.3)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_name = 'inception_transfer'\n",
    "model_dict[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mayM6yzi6TAz",
   "metadata": {
    "id": "mayM6yzi6TAz"
   },
   "source": [
    "two layers smaller conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hLI_cugbhx08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1642492711056,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "hLI_cugbhx08",
    "outputId": "b826fb91-6513-4260-be8b-6dfa7951c0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_94 (Conv2D)          (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 147, 147, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 170528)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               21827712  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,837,985\n",
      "Trainable params: 21,837,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# two layer small net\n",
    "\n",
    "cnn = tf.keras.Sequential()\n",
    "\n",
    "# convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(300, 300, 3)))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2nd Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten the layer\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "cnn.add(tf.keras.layers.Dense(activation = 'relu', units = 128))\n",
    "cnn.add(tf.keras.layers.Dense(activation = 'sigmoid', units = 1))\n",
    "\n",
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = cnn\n",
    "model_name = 'cnn_model_conv_2L'\n",
    "model.summary()\n",
    "\n",
    "model_dict['cnn_model_conv_2L']=model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EnBct0_X6bL0",
   "metadata": {
    "id": "EnBct0_X6bL0"
   },
   "source": [
    "Conv net with three layers, and drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OwJ__E-RxYPF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1642492715680,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "OwJ__E-RxYPF",
    "outputId": "387563fb-dbb2-48a1-b348-dec03ca1a32e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " activation_94 (Activation)  (None, 298, 298, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 149, 149, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 147, 147, 32)      9248      \n",
      "                                                                 \n",
      " activation_95 (Activation)  (None, 147, 147, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " activation_96 (Activation)  (None, 71, 71, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 78400)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                5017664   \n",
      "                                                                 \n",
      " activation_97 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_98 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,046,369\n",
      "Trainable params: 5,046,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "\n",
    "\n",
    "input_shape = (300, 300, 3)\n",
    "model = tf.keras.Sequential()\n",
    "# first conv layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# second \n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# third\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss= \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "model_name = 'cnn_model_conv_3L_dropout'\n",
    "\n",
    "model_dict['cnn_model_conv_3L_dropout'] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DxvJ-uud6mX0",
   "metadata": {
    "id": "DxvJ-uud6mX0"
   },
   "source": [
    "maybe two many convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NeGSh61FWn6m",
   "metadata": {
    "id": "NeGSh61FWn6m"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "#     # This is the first convolution\n",
    "#     tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     # The second convolution\n",
    "#     # tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # # The third convolution\n",
    "#     # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # # The fourth convolution\n",
    "#     # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # # The fifth convolution\n",
    "#     # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # Flatten the results to feed into a DNN\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     # 512 neuron hidden layer\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yobi4g_JUDwB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1824402,
     "status": "ok",
     "timestamp": 1642496862890,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "yobi4g_JUDwB",
    "outputId": "3ac7a29e-2747-485b-b663-fac465ed7db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training started: inception_transfer\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 1803s 11s/step - loss: 0.7401 - acc: 0.9276 - val_loss: 153.4158 - val_acc: 0.4259\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 69s 440ms/step - loss: 0.1392 - acc: 0.9621 - val_loss: 23269.4199 - val_acc: 0.5139\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 69s 441ms/step - loss: 0.1022 - acc: 0.9737 - val_loss: 6.9470 - val_acc: 0.7269\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 70s 442ms/step - loss: 0.0713 - acc: 0.9813 - val_loss: 6.3009 - val_acc: 0.8241\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 70s 448ms/step - loss: 0.0623 - acc: 0.9825 - val_loss: 0.1197 - val_acc: 0.9861\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 70s 442ms/step - loss: 0.0560 - acc: 0.9833 - val_loss: 29.1338 - val_acc: 0.8796\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 70s 447ms/step - loss: 0.0476 - acc: 0.9860 - val_loss: 0.0668 - val_acc: 0.9722\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 71s 452ms/step - loss: 0.0464 - acc: 0.9884 - val_loss: 1.3676 - val_acc: 0.8981\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 71s 451ms/step - loss: 0.0427 - acc: 0.9896 - val_loss: 2.2721 - val_acc: 0.8333\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 71s 452ms/step - loss: 0.0269 - acc: 0.9934 - val_loss: 0.0452 - val_acc: 0.9861\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 70s 448ms/step - loss: 0.0379 - acc: 0.9904 - val_loss: 0.0861 - val_acc: 0.9815\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 71s 449ms/step - loss: 0.0270 - acc: 0.9942 - val_loss: 0.0695 - val_acc: 0.9861\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 70s 448ms/step - loss: 0.0223 - acc: 0.9940 - val_loss: 3.6474 - val_acc: 0.7269\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 71s 448ms/step - loss: 0.0331 - acc: 0.9938 - val_loss: 0.8990 - val_acc: 0.8472\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 71s 449ms/step - loss: 0.0302 - acc: 0.9934 - val_loss: 3.5195 - val_acc: 0.5556\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/data science/02_chest_x_ray/inception_transfer/assets\n",
      "model training started: cnn_model_conv_2L\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 70s 442ms/step - loss: 0.4742 - accuracy: 0.8776 - val_loss: 0.2581 - val_accuracy: 0.8981\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 67s 427ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.0959 - val_accuracy: 0.9491\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 67s 427ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.2453 - val_accuracy: 0.8981\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 67s 425ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.2270 - val_accuracy: 0.9306\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 67s 423ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.1028 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 67s 427ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3369 - val_accuracy: 0.9167\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 67s 425ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.1571 - val_accuracy: 0.9491\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/data science/02_chest_x_ray/cnn_model_conv_2L/assets\n",
      "model training started: cnn_model_conv_3L_dropout\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 69s 433ms/step - loss: 0.3302 - accuracy: 0.8515 - val_loss: 0.2296 - val_accuracy: 0.9398\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 66s 423ms/step - loss: 0.2024 - accuracy: 0.9332 - val_loss: 0.3678 - val_accuracy: 0.8843\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 67s 423ms/step - loss: 0.1562 - accuracy: 0.9526 - val_loss: 0.2017 - val_accuracy: 0.9213\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 67s 424ms/step - loss: 0.1184 - accuracy: 0.9615 - val_loss: 0.2922 - val_accuracy: 0.9028\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 67s 426ms/step - loss: 0.1081 - accuracy: 0.9673 - val_loss: 0.2436 - val_accuracy: 0.9259\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 67s 425ms/step - loss: 0.0921 - accuracy: 0.9731 - val_loss: 0.1238 - val_accuracy: 0.9722\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 66s 422ms/step - loss: 0.0783 - accuracy: 0.9783 - val_loss: 0.1735 - val_accuracy: 0.9630\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 66s 421ms/step - loss: 0.0777 - accuracy: 0.9783 - val_loss: 0.1903 - val_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 66s 422ms/step - loss: 0.0778 - accuracy: 0.9765 - val_loss: 0.5303 - val_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 67s 424ms/step - loss: 0.0655 - accuracy: 0.9789 - val_loss: 0.1948 - val_accuracy: 0.9352\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 66s 424ms/step - loss: 0.0536 - accuracy: 0.9813 - val_loss: 0.3503 - val_accuracy: 0.9213\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/data science/02_chest_x_ray/cnn_model_conv_3L_dropout/assets\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "  print(f'model training started: {model_name}')\n",
    "  # model.summary()\n",
    "  history = model.fit(\n",
    "      train_generator,\n",
    "      validation_data=validation_generator,\n",
    "      epochs=20,\n",
    "      verbose=1, callbacks=[callback])\n",
    "  model.save(os.path.join('/content/drive/MyDrive/data science/02_chest_x_ray', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zbwln2ILDk_J",
   "metadata": {
    "id": "zbwln2ILDk_J"
   },
   "outputs": [],
   "source": [
    "# model_name = model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t7D2QRqIDmZp",
   "metadata": {
    "id": "t7D2QRqIDmZp"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KEgOFY0fuL6H",
   "metadata": {
    "id": "KEgOFY0fuL6H"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rqKRG_N4uQ38",
   "metadata": {
    "executionInfo": {
     "elapsed": 9493,
     "status": "ok",
     "timestamp": 1642961588024,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "rqKRG_N4uQ38"
   },
   "outputs": [],
   "source": [
    "# model_name = 'cnn_model_conv_2'\n",
    "# model_name = 'inception_transfer'\n",
    "# model_name = 'cnn_model_conv_3L_dropout'\n",
    "model_name = 'cnn_model_conv_2L'\n",
    "\n",
    "from tensorflow import keras\n",
    "# model = keras.models.load_model('path/to/location')\n",
    "# model_name = 'cnn_model_3_layer_20211209'\n",
    "model = keras.models.load_model(os.path.join('/content/drive/MyDrive/data science/02_chest_x_ray', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dgrS7vqwt2u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1642961433955,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "8dgrS7vqwt2u",
    "outputId": "c831f419-e7c6-46d1-909c-6a7e22b11f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_datagen = ImageDataGenerator(rescale=1/255)\n",
    "data_generator = data_datagen.flow_from_directory(\n",
    "        # validation_dir,\n",
    "        test_dir,\n",
    "        batch_size = 32,\n",
    "        target_size=(300, 300),\n",
    "        class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "W-DgX1zEfgJ7",
   "metadata": {
    "executionInfo": {
     "elapsed": 7239,
     "status": "ok",
     "timestamp": 1642961599968,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "W-DgX1zEfgJ7"
   },
   "outputs": [],
   "source": [
    "# get the predicted value\n",
    "y_pred_proba_0 = model.predict(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "av4Q5n-SsuXM",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1642961599968,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "av4Q5n-SsuXM"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = list(np.reshape(y_pred_proba_0, -1))\n",
    "y = list(data_generator.classes)\n",
    "file_names = data_generator.filenames\n",
    "data_dict = {'file_name': list(file_names), \n",
    "             'y': y,\n",
    "             \"y_pred_proba\": y_pred_proba}\n",
    "df_preds = pd.DataFrame(data_dict)\n",
    "df_preds['y_pred'] = df_preds['y_pred_proba'].map(lambda x: 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "jVPOevMnzYu0",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1642961599969,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "jVPOevMnzYu0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "precision = precision_score(y_true= df_preds['y'], y_pred = df_preds['y_pred'])\n",
    "recall = recall_score(y_true= df_preds['y'], y_pred = df_preds['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6lTAg7UC0C6N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1642961599969,
     "user": {
      "displayName": "Ryan S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTFArVLYUf8QlJ37yK3shq_WYc3yWMKO47Bjuz-Q=s64",
      "userId": "09131399502541644458"
     },
     "user_tz": 480
    },
    "id": "6lTAg7UC0C6N",
    "outputId": "7deda99b-18f6-4e12-dba7-0d303d00f896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: cnn_model_conv_2L\n",
      "precision: 0.7613412228796844\n",
      "recall: 0.9897435897435898\n"
     ]
    }
   ],
   "source": [
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LA5Y0oupHaEN",
   "metadata": {
    "id": "LA5Y0oupHaEN"
   },
   "outputs": [],
   "source": [
    "# model_name: inception_transfer\n",
    "# precision: 0.7729083665338645\n",
    "# recall: 0.9948717948717949\n",
    "\n",
    "# model_name: cnn_model_conv_3L_dropout\n",
    "# precision: 0.751953125\n",
    "# recall: 0.9871794871794872\n",
    "\n",
    "# model_name: cnn_model_conv_2L\n",
    "# precision: 0.7613412228796844\n",
    "# recall: 0.9897435897435898\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gifl5OrJHbEj",
   "metadata": {
    "id": "Gifl5OrJHbEj"
   },
   "source": [
    "# inception network: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tRh8H8vYHahm",
   "metadata": {
    "id": "tRh8H8vYHahm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zq325GpEVD11",
   "metadata": {
    "id": "zq325GpEVD11"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nGAsnBmapM6F",
   "metadata": {
    "id": "nGAsnBmapM6F"
   },
   "outputs": [],
   "source": [
    "# compare the actual vs predicted \n",
    "# data_dict = {'file_name': list(file_names), \n",
    "#              'y': y,\n",
    "#              \"y_pred_proba\": preds_1}\n",
    "# df_preds = pd.DataFrame(data_dict)\n",
    "# df_preds['y_pred'] = df_preds['y_pred_proba'].map(lambda x: 1 if x>0.5 else 0)\n",
    "# df_preds['correct_prepdiction_flag'] = (df_preds['y_pred'] == df_preds['y']).astype(int)\n",
    "# df_preds['correct_prediction_flag'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NIFnZJtKqa4j",
   "metadata": {
    "id": "NIFnZJtKqa4j"
   },
   "outputs": [],
   "source": [
    "# df_preds.to_csv(os.path.join(project_dir, 'result', f'df_preds_{model_name}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FJbXnEEygPja",
   "metadata": {
    "id": "FJbXnEEygPja"
   },
   "outputs": [],
   "source": [
    "# model.save(os.path.join('/content/drive/MyDrive/data science/02_chest_x_ray', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UUCaJ0zJDg93",
   "metadata": {
    "id": "UUCaJ0zJDg93"
   },
   "outputs": [],
   "source": [
    "# len(file_names)\n",
    "# total_images = data_generator.n\n",
    "# batch_size = 32\n",
    "# steps = total_images/batch_size \n",
    "# round(steps)\n",
    "\n",
    "# data_generator.reset()\n",
    "# #iterations to cover all data, so if batch is 5, it will take total_images/5  iteration \n",
    "# x , y = [] , []\n",
    "# for i in range(round(steps)):\n",
    "#     a , b = data_generator.next()\n",
    "#     y.extend(b)  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Pneumonia_01d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
